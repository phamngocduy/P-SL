{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONG3CNbxcLKmeHTu+wzBXQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from torch import nn, optim"],"metadata":{"id":"Y5xZgqz-FCBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Conv2d(nn.Module):\n","  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dropout=0, groups=1):\n","    super().__init__()\n","    self.model = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, 1, groups),\n","        nn.BatchNorm2d(num_features=out_channels), nn.ReLU(inplace=True)\n","    )\n","    if dropout: self.model.append(nn.Dropout(dropout))\n","\n","  def forward(self, input):\n","    return self.model(input)\n","\n","class Module(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","  def init_loader(self, dataset, batch):\n","    self.accuracy = []\n","    self.loader = DataLoaderGPU(dataset, batch, True)\n","\n","  def init_optim(self, epochs, lr):\n","    self.optimizer = optim.Adam(self.parameters(), lr)\n","    self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, epochs)\n","\n","  def initialize(self, dataset, epochs, batch, lr):\n","    self.init_loader(dataset, batch)\n","    self.init_optim(epochs, lr)\n","\n","  def zero_grad(self):\n","    self.optimizer.zero_grad()\n","\n","  def optim_step(self):\n","    self.optimizer.step()\n","\n","  def sched_step(self):\n","    self.scheduler.step()\n","\n","  def backward(self, loss):\n","    loss.backward()"],"metadata":{"id":"QZwiHqHXFDxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMsumwCTEz1s"},"outputs":[],"source":["class VGGNet(Module):\n","  def __init__(self, layers, in_channels, dropout):\n","    super().__init__()\n","    self.client = nn.Sequential()\n","    self.server = nn.Sequential()\n","    kernel_size, padding = 3, 1\n","    for out_channels, stride in layers:\n","      self.server.append(Conv2d(in_channels, out_channels, kernel_size, stride, padding, dropout))\n","      in_channels = out_channels\n","\n","  def mobile(self, in_channels, out_channels, dropout):\n","    return nn.Sequential(\n","        #Conv2d(in_channels, 4, 1, 1, 0, 0),\n","        #Conv2d(4, out_channels, 3, 2, 1, 0, 4)\n","        Conv2d(in_channels, int(out_channels/2), 3, 1, 1, dropout),\n","        Conv2d(int(out_channels/2), out_channels, 3, 2, 1, dropout)\n","    )\n","\n","  def forward(self, input):\n","    return self.server(self.client(input))\n","\n","class CNN_3(VGGNet):\n","  def __init__(self, in_channels, num_classes, dropout=(0.2,0.3)):\n","    super().__init__([(64,2)], 32, dropout[1])\n","    self.client = Conv2d(in_channels, 32, 3, 2, 1, dropout[0])\n","    self.server.append(nn.Flatten())\n","    self.server.append(nn.Linear(3136, 128))\n","    self.server.append(nn.BatchNorm1d(128))\n","    self.server.append(nn.Linear(128, num_classes))\n","\n","class VGG_7(VGGNet):\n","  def __init__(self, in_channels, num_classes, dropout=(0.2,0.3)):\n","    super().__init__([(64,2), (128,2), (256,2), (512,2)], 32, dropout[1])\n","    self.client = self.mobile(in_channels, 32, dropout[0])\n","    self.server.append(nn.Flatten())\n","    self.server.append(nn.Linear(512, num_classes))\n","\n","class VGG_11(VGGNet):\n","  def __init__(self, in_channels, num_classes, dropout=(0.2,0.3)):\n","    super().__init__([(128,1), (128,2), (256,1), (256,2), (512,1), (512,2), (512,1), (512,2)], 64, dropout[1])\n","    self.client = self.mobile(in_channels, 64, dropout[0])\n","    self.server.append(nn.Flatten())\n","    self.server.append(nn.Linear(512, num_classes))"]},{"cell_type":"code","source":["class Client(Module):\n","  def __init__(self, model):\n","    super().__init__()\n","    self.client = model\n","\n","  def forward(self, input):\n","    self.output = self.client(input)\n","    return self.output.detach()#.clone()\n","\n","  def backward(self, grad):\n","    self.output.backward(grad)\n","\n","\n","class Server(Module):\n","  def __init__(self, model):\n","    super().__init__()\n","    self.server = model\n","\n","  def initialize(self, tester, epochs, lr):\n","    self.loader = tester\n","    self.init_optim(epochs, lr)\n","\n","  def forward(self, input):\n","    self.input = input.requires_grad_(True)\n","    return self.server(self.input)\n","\n","  def backward(self, loss):\n","    loss.backward()\n","    return self.input.grad.detach()#.clone()"],"metadata":{"id":"jkPKFEePFS2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SplitNN:\n","  def __init__(self, clients, server):\n","    self.clients = [c.cuda() for c in clients]\n","    self.server = server.cuda()\n","\n","  def initialize(self, datasets, tester, epochs, batch, lr):\n","    for client, data in zip(self.clients, datasets):\n","      client.initialize(data, epochs, batch, lr)\n","    self.server.initialize(tester, epochs, lr)\n","    self.cached = [[] for c in self.clients]\n","\n","  def evaluate(self):\n","    with torch.no_grad():\n","      self.server.eval()\n","      for client in self.clients:\n","        client.eval()\n","        client.accuracy.append(0)\n","        for images, labels in self.server.loader:\n","          output = self.server(client(images)).argmax(1)\n","          client.accuracy[-1] += (output == labels).sum().item()\n","        client.accuracy[-1] /= len(self.server.loader.dataset)\n","\n","  def train_network(self, epoch, private=True, sequence=False, federate=False, caches=None):\n","    local = lambda m, p: m.client[0] if p else m\n","    self.server.train()\n","    if sequence: #SL\n","      model = local(self.clients[-1], private).state_dict()\n","    for idx, client in enumerate(self.clients):\n","      if caches: #Our\n","        index = list(np.arange(len(caches))); del index[idx]\n","        cached = [self.cached[i] for i in index]\n","        maxlen = [caches[i] for i in index]\n","      if sequence: #SL\n","        local(client, private).load_state_dict(model)\n","      client.train()\n","      for images, labels in client.loader:\n","        client.zero_grad(), self.server.zero_grad()\n","        #output = self.server(client(images))\n","        output = client(images)\n","        #always cache data\n","        if len(labels) == batch:\n","          self.cached[idx] = (output.clone(), labels)\n","        else:\n","          self.cached[idx] = (torch.cat([self.cached[idx][0], output.clone()]),\n","                              torch.cat([self.cached[idx][1], labels]))\n","        if caches and epoch > 0:\n","          indices = [torch.randperm(len(c)) for _,c in cached]\n","          images_cached = [c[0][i][:m] for c,i,m in zip(cached,indices,maxlen)]\n","          labels_cached = [c[1][i][:m] for c,i,m in zip(cached,indices,maxlen)]\n","          output = torch.cat([output] + images_cached)\n","          labels = torch.cat([labels] + labels_cached)\n","        output = self.server(output)\n","        loss = F.cross_entropy(output, labels)\n","        grads = self.server.backward(loss)\n","        client.backward(grads[:len(client.output)])\n","        #client.backward(self.server.backward(loss))\n","        client.optim_step(), self.server.optim_step()\n","      client.sched_step()\n","      if sequence: #SL\n","        model = local(client, private).state_dict()\n","    self.server.sched_step()\n","    if federate: #SFL\n","      models = [local(c, private).state_dict() for c in self.clients]\n","      for key in models[0]:\n","        for i in range(1, len(models)):\n","          models[0][key] += models[i][key]\n","        if models[0][key].type().split('.')[-1] == 'LongTensor':\n","          torch.div(models[0][key], len(models), rounding_mode='floor')\n","        else: models[0][key] /= len(models)\n","      for client in self.clients:\n","        local(client, private).load_state_dict(models[0])"],"metadata":{"id":"ECym8zX4A90W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SplitNN_2(SplitNN):\n","  def __init__(self, clients, exists):\n","    super().__init__(clients, exists.server)\n","    self.exists = exists\n","\n","  def initialize(self, datasets, tester, epochs, batch, lr):\n","    super().initialize(datasets, tester, epochs, batch, lr)\n","    for c in self.exists.clients: c.accuracy = []\n","    self.cached = self.exists.cached\n","\n","  def evaluate(self):\n","    super().evaluate()\n","    self.exists.evaluate()\n","\n","  def all_clients(self):\n","    return self.exists.clients + self.clients\n","\n","  def train_network(self, epoch, caches=None):\n","    self.server.train()\n","    for idx, client in enumerate(self.clients):\n","      client.train()\n","      for images, labels in client.loader:\n","        client.zero_grad(), self.server.zero_grad()\n","        output = client(images)\n","        if caches: #Our\n","          indices = [torch.randperm(len(c)) for _,c in self.cached]\n","          images_cached = [c[0][i][:m] for c,i,m in zip(self.cached,indices,caches)]\n","          labels_cached = [c[1][i][:m] for c,i,m in zip(self.cached,indices,caches)]\n","          output = torch.cat([output] + images_cached)\n","          labels = torch.cat([labels] + labels_cached)\n","        output = self.server(output)\n","        loss = F.cross_entropy(output, labels)\n","        grads = self.server.backward(loss)\n","        client.backward(grads[:len(client.output)])\n","        client.optim_step(), self.server.optim_step()\n","      client.sched_step()\n","    self.server.sched_step()"],"metadata":{"id":"ZicCvrhx-51A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_caching(self, epoch, caches):\n","  caches = [int(c)+1 for c in caches]\n","  self.server.train()\n","  for idx, client in enumerate(self.clients):\n","    client.train()\n","    for itr, (images, labels) in enumerate(client.loader):\n","      client.zero_grad(), self.server.zero_grad()\n","      output = client(images)\n","\n","      images_cached = [self.cached[i][0][0] for i in range(len(self.cached))]\n","      labels_cached = [self.cached[i][0][1] for i in range(len(self.cached))]\n","      cached_index = [torch.randperm(len(c)) for c in labels_cached]\n","      images_cached = [c[cached_index[i]][:caches[i]] for i, c in enumerate(images_cached)]\n","      labels_cached = [c[cached_index[i]][:caches[i]] for i, c in enumerate(labels_cached)]\n","      output = torch.cat([output, torch.cat(images_cached)])\n","      labels = torch.cat([labels, torch.cat(labels_cached)])\n","\n","      output = self.server(output)\n","      loss = F.cross_entropy(output, labels)\n","      grads = self.server.backward(loss)\n","      client.backward(grads[:len(client.output)])\n","      client.optim_step(), self.server.optim_step()\n","    client.sched_step()\n","  self.server.sched_step()"],"metadata":{"id":"gmEuWqzE8eYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Autodecoder(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","  def train_model(self, client, tester, epochs, lr=0.001):\n","    optimizer = optim.Adam(self.parameters(), lr)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n","    self.accuracy = []; client.eval()\n","    for bar, epoch in tqdn(range(epochs)):\n","      self.train()\n","      for images, _ in client.loader:\n","        optimizer.zero_grad()\n","        with torch.no_grad():\n","          output = client(images)\n","        output = self(output)\n","        loss = F.mse_loss(output, images)\n","        loss.backward()\n","        optimizer.step()\n","        bar.set_postfix_str(f'MSE:{loss.item()}')\n","      scheduler.step()\n","\n","      self.eval()\n","      with torch.no_grad():\n","        self.accuracy.append(0)\n","        for images, _ in tester.loader:\n","          output = self(client(images))\n","          loss = F.mse_loss(output, images)\n","          self.accuracy[-1] += loss.item()\n","        self.accuracy[-1] /= len(tester.loader)\n","      plot_progress([self], locals())"],"metadata":{"id":"RATU7SUycgmt"},"execution_count":null,"outputs":[]}]}